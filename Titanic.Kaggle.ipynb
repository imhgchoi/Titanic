{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"D:/rawDataFiles/titanic_train.csv\")\n",
    "question = pd.read_csv(\"D:/rawDataFiles/titanic_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding & Dealing with NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Title'] = data['Name'].apply(get_title)\n",
    "question['Title'] = question['Name'].apply(get_title)\n",
    "\n",
    "data['HasCabin'] = data['Cabin'].apply(lambda x: 0 if type(x) == float else 1)\n",
    "question['HasCabin'] = question['Cabin'].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
    "question['FamilySize'] = question['SibSp'] + question['Parch'] + 1\n",
    "\n",
    "data['Solo'] = data['FamilySize'].apply(lambda x: 1 if x==1 else 0)\n",
    "question['Solo'] = question['FamilySize'].apply(lambda x: 1 if x==1 else 0)\n",
    "\n",
    "data['Embarked'] = data['Embarked'].fillna('S')\n",
    "question['Embarked'] = question['Embarked'].fillna('S')\n",
    "data['Embarked'] = data['Embarked'].apply(lambda x: 1 if x=='C' else x).apply(lambda x: 2 if x=='Q' else x).apply(lambda x: 3 if x=='S' else x)\n",
    "question['Embarked'] = question['Embarked'].apply(lambda x: 1 if x=='C' else x).apply(lambda x: 2 if x=='Q' else x).apply(lambda x: 3 if x=='S' else x)\n",
    "\n",
    "data['Fare'] = data['Fare'].fillna(data['Fare'].median())\n",
    "question['Fare'] = question['Fare'].fillna(data['Fare'].median())\n",
    "\n",
    "data['Sex'] = data['Sex'].apply(lambda x: 1 if x=='male' else 0)\n",
    "question['Sex'] = question['Sex'].apply(lambda x: 1 if x=='male' else 0)\n",
    "\n",
    "title_list = data.Title.unique()\n",
    "title_age_avg = []\n",
    "for title in title_list :\n",
    "    title_age_avg.append(title + \" : \" + str(data[data.Title == title]['Age'].mean()))\n",
    "title_age_dic = {'Mr':4, 'Mrs':4, 'Miss':3, 'Master':1, 'Don':4, 'Dona':4, 'Rev':4, 'Dr':4, 'Mme':3, 'Ms':3, 'Major':5, 'Lady':5, 'Sir':5, 'Mlle':3, 'Col':5, 'Capt':6, 'Countess':4, 'Jonkheer':4}\n",
    "data['TitleEncoding'] = data['Title'].apply(lambda x: title_age_dic[x])\n",
    "question['TitleEncoding'] = question['Title'].apply(lambda x: title_age_dic[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in NA in Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train R^2 : 0.402443198814\n",
      "test R^2 : 0.438191402185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "age_col = ['Age','Pclass','SibSp','FamilySize','TitleEncoding','Solo']\n",
    "age_data = data[age_col].dropna()\n",
    "y = age_data['Age']\n",
    "X = age_data[age_col[1:]]\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X= DataFrame(scaler.transform(X))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=1)\n",
    "\n",
    "ageNN = MLPRegressor(\n",
    "    hidden_layer_sizes=(10,9,8),\n",
    "    activation='relu',\n",
    "    alpha=0.1,\n",
    "    max_iter=10000,\n",
    "    random_state=1\n",
    ")\n",
    "ageNN.fit(X_train,y_train)\n",
    "print('train R^2 : ' + str(ageNN.score(X_train, y_train)))\n",
    "print('test R^2 : ' + str(ageNN.score(X_test, y_test)))\n",
    "ageNN.fit(X,y)\n",
    "nanlist = []\n",
    "for i in range(891):\n",
    "    if np.isnan(data.Age[i]):\n",
    "        nanlist.append(i)\n",
    "X=[]\n",
    "for i in nanlist :\n",
    "    X.append([data.Pclass[i], data.SibSp[i], data.FamilySize[i], data.TitleEncoding[i], data.Solo[i]])\n",
    "X= DataFrame(scaler.fit(X).transform(X))\n",
    "Age_pred_result = ageNN.predict(X)\n",
    "c=0\n",
    "for i in range(891):\n",
    "   if np.isnan(data.Age[i]):\n",
    "       data.Age[i] = Age_pred_result[c]\n",
    "       c+=1\n",
    "\n",
    "nanlist = []\n",
    "for i in range(418):\n",
    "    if np.isnan(question.Age[i]):\n",
    "        nanlist.append(i)\n",
    "X=[]\n",
    "for i in nanlist :\n",
    "    X.append([question.Pclass[i], question.SibSp[i], question.FamilySize[i], question.TitleEncoding[i], question.Solo[i]])\n",
    "X= DataFrame(scaler.fit(X).transform(X))\n",
    "Age_pred_result = ageNN.predict(X)\n",
    "c=0\n",
    "for i in range(418):\n",
    "   if np.isnan(question.Age[i]):\n",
    "       question.Age[i] = Age_pred_result[c]\n",
    "       c+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_to_use = ['Survived','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked','HasCabin','FamilySize','TitleEncoding','Solo']\n",
    "data_nontree = data.copy()[columns_to_use]\n",
    "question_nontree = question.copy()[columns_to_use[1:]]\n",
    "data_tree = data.copy()[columns_to_use]\n",
    "question_tree = question.copy()[columns_to_use[1:]]\n",
    "\n",
    "#NONTREE\n",
    "data_nontree_X = data_nontree[columns_to_use[1:]]\n",
    "data_nontree_y = data_nontree['Survived']\n",
    "nt_train_X, nt_test_X, nt_train_y, nt_test_y = train_test_split(data_nontree_X, data_nontree_y,random_state=1)\n",
    "scaler.fit(nt_train_X[columns_to_use[1:]])\n",
    "nt_train_X = DataFrame(scaler.transform(nt_train_X))\n",
    "nt_test_X = DataFrame(scaler.transform(nt_test_X))\n",
    "\n",
    "#TREE\n",
    "data_tree_X = data_tree[columns_to_use[1:]]\n",
    "data_tree_y = data_tree['Survived']\n",
    "t_train_X, t_test_X, t_train_y, t_test_y = train_test_split(data_tree_X, data_tree_y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ Non-Tree Classifiers ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$ ANN $$\n",
      "train accuracy : 0.814371257485\n",
      "test accuracy : 0.811659192825\n",
      "train AUC : 0.794166578515\n",
      "test AUC : 0.795230263158\n"
     ]
    }
   ],
   "source": [
    "ANN = MLPClassifier(\n",
    "    hidden_layer_sizes=(10,9),\n",
    "    activation='relu',\n",
    "    alpha=3,\n",
    "    max_iter=100000,\n",
    "    random_state=1\n",
    ")\n",
    "ANN.fit(nt_train_X,nt_train_y)\n",
    "print(\"$$ ANN $$\")\n",
    "print('train accuracy : ' + str(ANN.score(nt_train_X, nt_train_y)))\n",
    "print('test accuracy : ' + str(ANN.score(nt_test_X, nt_test_y)))\n",
    "print('train AUC : ' + str(roc_auc_score(np.array(nt_train_y),np.array(ANN.predict(nt_train_X)))))\n",
    "print('test AUC : ' + str(roc_auc_score(np.array(nt_test_y),np.array(ANN.predict(nt_test_X)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$ SVM $$\n",
      "train accuracy : 0.796407185629\n",
      "test accuracy : 0.789237668161\n",
      "train AUC : 0.773221652707\n",
      "test AUC : 0.772985197368\n"
     ]
    }
   ],
   "source": [
    "SVM = svm.SVC(\n",
    "    C = 1\n",
    ")\n",
    "SVM.fit(nt_train_X,nt_train_y)\n",
    "print(\"$$ SVM $$\")\n",
    "print('train accuracy : ' + str(SVM.score(nt_train_X, nt_train_y)))\n",
    "print('test accuracy : ' + str(SVM.score(nt_test_X, nt_test_y)))\n",
    "print('train AUC : ' + str(roc_auc_score(np.array(nt_train_y),np.array(SVM.predict(nt_train_X)))))\n",
    "print('test AUC : ' + str(roc_auc_score(np.array(nt_test_y),np.array(SVM.predict(nt_test_X)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$ LOG $$\n",
      "train accuracy : 0.812874251497\n",
      "test accuracy : 0.811659192825\n",
      "train AUC : 0.790469000933\n",
      "test AUC : 0.795230263158\n"
     ]
    }
   ],
   "source": [
    "GLM = LogisticRegression()\n",
    "GLM.fit(nt_train_X,nt_train_y)\n",
    "print(\"$$ LOG $$\")\n",
    "print('train accuracy : ' + str(GLM.score(nt_train_X, nt_train_y)))\n",
    "print('test accuracy : ' + str(GLM.score(nt_test_X, nt_test_y)))\n",
    "print('train AUC : ' + str(roc_auc_score(np.array(nt_train_y),np.array(GLM.predict(nt_train_X)))))\n",
    "print('test AUC : ' + str(roc_auc_score(np.array(nt_test_y),np.array(GLM.predict(nt_test_X)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ Tree Classifiers ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$ RF $$\n",
      "train accuracy : 0.844311377246\n",
      "test accuracy : 0.807174887892\n",
      "train AUC : 0.826285978055\n",
      "test AUC : 0.789967105263\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier(\n",
    "    n_estimators=600,\n",
    "    max_depth=3,\n",
    "    max_features=6,\n",
    "    random_state=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "RF.fit(t_train_X, t_train_y)\n",
    "print(\"$$ RF $$\")\n",
    "print('train accuracy : ' + str(RF.score(t_train_X, t_train_y)))\n",
    "print('test accuracy : ' + str(RF.score(t_test_X, t_test_y)))\n",
    "print('train AUC : ' + str(roc_auc_score(np.array(t_train_y),np.array(RF.predict(t_train_X)))))\n",
    "print('test AUC : ' + str(roc_auc_score(np.array(t_test_y),np.array(RF.predict(t_test_X)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$ ET $$\n",
      "train accuracy : 0.835329341317\n",
      "test accuracy : 0.80269058296\n",
      "train AUC : 0.812466942983\n",
      "test AUC : 0.784703947368\n"
     ]
    }
   ],
   "source": [
    "ET = ExtraTreesClassifier(\n",
    "    n_estimators=600,\n",
    "    max_depth=3,\n",
    "    max_features=6,\n",
    "    random_state=1,\n",
    "    n_jobs=-1   \n",
    ")\n",
    "ET.fit(t_train_X, t_train_y)\n",
    "print(\"$$ ET $$\")\n",
    "print('train accuracy : ' + str(ET.score(t_train_X, t_train_y)))\n",
    "print('test accuracy : ' + str(ET.score(t_test_X, t_test_y)))\n",
    "print('train AUC : ' + str(roc_auc_score(np.array(t_train_y),np.array(ET.predict(t_train_X)))))\n",
    "print('test AUC : ' + str(roc_auc_score(np.array(t_test_y),np.array(ET.predict(t_test_X)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$ GBDT $$\n",
      "train accuracy : 0.859281437126\n",
      "test accuracy : 0.798206278027\n",
      "train AUC : 0.825612816987\n",
      "test AUC : 0.771299342105\n"
     ]
    }
   ],
   "source": [
    "GBDT = GradientBoostingClassifier(\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    "    max_features=6,\n",
    "    random_state=None\n",
    ")\n",
    "GBDT.fit(t_train_X, t_train_y)\n",
    "print(\"$$ GBDT $$\")\n",
    "print('train accuracy : ' + str(GBDT.score(t_train_X, t_train_y)))\n",
    "print('test accuracy : ' + str(GBDT.score(t_test_X, t_test_y)))\n",
    "print('train AUC : ' + str(roc_auc_score(np.array(t_train_y),np.array(GBDT.predict(t_train_X)))))\n",
    "print('test AUC : ' + str(roc_auc_score(np.array(t_test_y),np.array(GBDT.predict(t_test_X)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$ ADA $$\n",
      "train accuracy : 0.796407185629\n",
      "test accuracy : 0.784753363229\n",
      "train AUC : 0.778241510958\n",
      "test AUC : 0.770435855263\n"
     ]
    }
   ],
   "source": [
    "ADA = AdaBoostClassifier(\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=300,\n",
    "    random_state=1\n",
    ")\n",
    "ADA.fit(t_train_X, t_train_y)\n",
    "print(\"$$ ADA $$\")\n",
    "print('train accuracy : ' + str(ADA.score(t_train_X, t_train_y)))\n",
    "print('test accuracy : ' + str(ADA.score(t_test_X, t_test_y)))\n",
    "print('train AUC : ' + str(roc_auc_score(np.array(t_train_y),np.array(ADA.predict(t_train_X)))))\n",
    "print('test AUC : ' + str(roc_auc_score(np.array(t_test_y),np.array(ADA.predict(t_test_X)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$ XGB $$\n",
      "train accuracy : 0.823353293413\n",
      "test accuracy : 0.80269058296\n",
      "train AUC : 0.798782540125\n",
      "test AUC : 0.784703947368\n"
     ]
    }
   ],
   "source": [
    "XGB = xgb.XGBClassifier(\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=100,\n",
    "    max_depth=2,\n",
    "    gamma=0.9,\n",
    "    nthread=-1\n",
    ")\n",
    "XGB.fit(t_train_X, t_train_y)\n",
    "print(\"$$ XGB $$\")\n",
    "print('train accuracy : ' + str(XGB.score(t_train_X, t_train_y)))\n",
    "print('test accuracy : ' + str(XGB.score(t_test_X, t_test_y)))\n",
    "print('train AUC : ' + str(roc_auc_score(np.array(t_train_y),np.array(XGB.predict(t_train_X)))))\n",
    "print('test AUC : ' + str(roc_auc_score(np.array(t_test_y),np.array(XGB.predict(t_test_X)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN + SVM + LOG + ADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = DataFrame({'ANN':ANN.predict(nt_train_X),'SVM':SVM.predict(nt_train_X),'LOG':GLM.predict(nt_train_X),'ADA':ADA.predict(t_train_X),'Actual':t_train_y})\n",
    "x=['ADA','ANN','LOG','SVM']\n",
    "X = result[x]\n",
    "y = result['Actual']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STACK : ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$ FINnn $$\n",
      "accuracy : 0.835329341317\n",
      "AUC : 0.812466942983\n"
     ]
    }
   ],
   "source": [
    "FINnn4 = MLPClassifier(\n",
    "    hidden_layer_sizes=(10,9),\n",
    "    activation='relu',\n",
    "    alpha=1,\n",
    "    max_iter=100000,\n",
    "    random_state=10\n",
    ")\n",
    "FINnn4.fit(X,y)\n",
    "print(\"$$ FINnn $$\")\n",
    "print('accuracy : ' + str(FINnn4.score(X,y)))\n",
    "print('AUC : ' + str(roc_auc_score(np.array(y),np.array(FINnn4.predict(X)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STACK : LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$ FINlog $$\n",
      "accuracy : 0.832335329341\n",
      "AUC : 0.810928289113\n"
     ]
    }
   ],
   "source": [
    "FINlog4 = LogisticRegression()\n",
    "FINlog4.fit(X,y)\n",
    "print(\"$$ FINlog $$\")\n",
    "print('accuracy : ' + str(FINlog4.score(X,y)))\n",
    "print('AUC : ' + str(roc_auc_score(np.array(y),np.array(FINlog4.predict(X)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN + SVM + LOG + ADA + ET + XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = DataFrame({'ANN':ANN.predict(nt_train_X),'SVM':SVM.predict(nt_train_X),'LOG':GLM.predict(nt_train_X),\n",
    "                    'ADA':ADA.predict(t_train_X),'ET':ET.predict(t_train_X),'XGB':XGB.predict(t_train_X),\n",
    "                    'Actual':t_train_y})\n",
    "x=['ADA','ANN','LOG','SVM','ET','XGB']\n",
    "X = result[x]\n",
    "y = result['Actual']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STACK : ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$ FINnn $$\n",
      "accuracy : 0.829341317365\n",
      "AUC : 0.808552992201\n"
     ]
    }
   ],
   "source": [
    "FINnn6 = MLPClassifier(\n",
    "    hidden_layer_sizes=(50,25),\n",
    "    activation='relu',\n",
    "    alpha=1,\n",
    "    max_iter=100000,\n",
    "    random_state=None\n",
    ")\n",
    "FINnn6.fit(X,y)\n",
    "print(\"$$ FINnn $$\")\n",
    "print('accuracy : ' + str(FINnn6.score(X,y)))\n",
    "print('AUC : ' + str(roc_auc_score(np.array(y),np.array(FINnn6.predict(X)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STACK : LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$ FINlog $$\n",
      "accuracy : 0.832335329341\n",
      "AUC : 0.810928289113\n"
     ]
    }
   ],
   "source": [
    "FINlog6 = LogisticRegression()\n",
    "FINlog6.fit(X,y)\n",
    "print(\"$$ FINlog $$\")\n",
    "print('accuracy : ' + str(FINlog6.score(X,y)))\n",
    "print('AUC : ' + str(roc_auc_score(np.array(y),np.array(FINlog6.predict(X)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler.fit(data[columns_to_use[1:]])\n",
    "data_nontree_X = DataFrame(scaler.transform(data_nontree_X))\n",
    "question_nontree = scaler.transform(question_nontree)\n",
    "\n",
    "ANN = MLPClassifier(\n",
    "    hidden_layer_sizes=(10,9),\n",
    "    activation='relu',\n",
    "    alpha=0.01,\n",
    "    max_iter=100000,\n",
    "    random_state=1\n",
    ")\n",
    "ANN.fit(data_nontree_X,data_nontree_y)\n",
    "\n",
    "SVM = svm.SVC()\n",
    "SVM.fit(data_nontree_X,data_nontree_y)\n",
    "\n",
    "GLM = LogisticRegression()\n",
    "GLM.fit(data_nontree_X,data_nontree_y)\n",
    "\n",
    "ADA = AdaBoostClassifier(\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=300,\n",
    "    random_state=0\n",
    ")\n",
    "ADA.fit(data_tree_X,data_tree_y)\n",
    "\n",
    "result = DataFrame({'ANN':ANN.predict(data_nontree_X),'SVM':SVM.predict(data_nontree_X),'LOG':GLM.predict(data_nontree_X),'ADA':ADA.predict(data_tree_X),'Actual':data_nontree_y})\n",
    "x=['ADA','ANN','LOG','SVM']\n",
    "FINlog4 = LogisticRegression()\n",
    "FINlog4.fit(result[x],result['Actual'])\n",
    "\n",
    "total = DataFrame({'ANN':ANN.predict(question_nontree),'SVM':SVM.predict(question_nontree),'GLM':GLM.predict(question_nontree),'ADA':ADA.predict(question_tree)})\n",
    "\n",
    "submission = pd.DataFrame({'PassengerId': question['PassengerId'], 'Survived':FINlog4.predict(total)})\n",
    "submission.to_csv(\"C:/Users/Froilan/Desktop/Repository/kaggleResultCSV/Titanic_python_stacking.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
